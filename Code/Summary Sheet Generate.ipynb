{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef35f5e-53cc-4012-801e-c7d19ee5f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6719f283-ccca-4927-8757-5fdbc3d7b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETTINGS YOU CAN EDIT =====================================\n",
    "\n",
    "xlsx_path = Path(\"Large_Model_Questions_WITH_BERTSCORE_PRF_debertaxlargemnli_Align.xlsx\")\n",
    "output_path = Path(\"Large_Model_Questions_WITH_BERTSCORE_PRF_debertaxlargemnli_Align_with_summary.xlsx\")\n",
    "\n",
    "ps_sheets = [\"PS1\", \"PS2\", \"PS3\", \"PS4\", \"PS5\"]\n",
    "\n",
    "# Canonical column names we want in the summary\n",
    "numeric_metrics = {\n",
    "    \"Avg Similarity\": \"Similarity\",\n",
    "    \"Avg Grade level\": \"Grade level\",\n",
    "    \"Avg Reading Ease\": \"Reading Ease\",\n",
    "    \"1--2\": \"sim_1_2_f1\",\n",
    "    \"2--3\": \"sim_2_3_f1\",\n",
    "    \"3--4\": \"sim_3_4_f1\",\n",
    "    \"4--5\": \"sim_4_5_f1\",\n",
    "    \"5--6\": \"sim_5_6_f1\",\n",
    "}\n",
    "\n",
    "bool_metrics = {\n",
    "    \"Bloom_Level_Check\": \"Assigned Level Check\",\n",
    "    \"Grade_compliant\": \"Grade Level Check\",\n",
    "    \"precision_compliant_rate\": \"precision_compliant\",\n",
    "    \"recall_compliant_rate\": \"recall_compliant\",\n",
    "    \"f1_compliant_rate\": \"f1_compliant\",\n",
    "}\n",
    "\n",
    "ordered_cols = list(numeric_metrics.keys()) + list(bool_metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff29edb-c16b-4ade-ac1d-29531ed311ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPERS ====================================================\n",
    "\n",
    "def find_column(df, target):\n",
    "    \"\"\"Case/space-insensitive column lookup.\"\"\"\n",
    "    target_clean = target.strip().lower()\n",
    "    for col in df.columns:\n",
    "        if col.strip().lower() == target_clean:\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_columns(df):\n",
    "    \"\"\"Strip whitespace in column names.\"\"\"\n",
    "    df = df.copy()\n",
    "    df.columns = [col.strip() for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def summarize_sheet(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Per-model summary for one PS sheet.\n",
    "\n",
    "    - Strips whitespace from column names.\n",
    "    - Forward-fills Model and Prompt to handle merged cells from Excel.\n",
    "    - Normalizes Model values (strip + upper) so names are consistent.\n",
    "    - Drops rows that don't contain a real question/metrics.\n",
    "    - Resolves metric columns case-insensitively.\n",
    "    - Computes:\n",
    "        * numeric means (Similarity, Grade level, Reading Ease, ...)\n",
    "        * boolean TRUE rates for compliance columns.\n",
    "    \"\"\"\n",
    "    df = normalize_columns(df)\n",
    "\n",
    "    # ---- forward-fill & standardize Model column ----\n",
    "    model_col = find_column(df, \"Model\")\n",
    "    if model_col is None:\n",
    "        raise KeyError(\n",
    "            f\"'Model' column not found in sheet. Columns present: {list(df.columns)}\"\n",
    "        )\n",
    "\n",
    "    # ffill the model column to account for merged cells in Excel\n",
    "    df[model_col] = df[model_col].ffill()\n",
    "\n",
    "    # rename to canonical \"Model\" if needed\n",
    "    if model_col != \"Model\":\n",
    "        df = df.rename(columns={model_col: \"Model\"})\n",
    "\n",
    "    # NORMALISE MODEL VALUES (this is the important new part)\n",
    "    df[\"Model\"] = (\n",
    "        df[\"Model\"]\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.upper()   # use .str.upper() so GPT4 == gpt4\n",
    "    )\n",
    "\n",
    "    # ---- forward-fill Prompt as well (merged cells) ----\n",
    "    prompt_col = find_column(df, \"Prompt\")\n",
    "    if prompt_col:\n",
    "        df[prompt_col] = df[prompt_col].ffill()\n",
    "        if prompt_col != \"Prompt\":\n",
    "            df = df.rename(columns={prompt_col: \"Prompt\"})\n",
    "\n",
    "    # ---- drop structural/blank rows (no real question / metrics) ----\n",
    "    q_col = find_column(df, \"Questions\")\n",
    "    if q_col:\n",
    "        df = df[df[q_col].notna()]\n",
    "\n",
    "    sim_col = find_column(df, \"Similarity\")\n",
    "    if sim_col:\n",
    "        df = df[df[sim_col].notna()]\n",
    "\n",
    "    # ---- normalize boolean-like columns (TRUE/FALSE strings) ----\n",
    "    for _, col in bool_metrics.items():\n",
    "        actual = find_column(df, col)\n",
    "        if actual:\n",
    "            df[actual] = df[actual].replace(\n",
    "                {\"TRUE\": True, \"FALSE\": False, \"true\": True, \"false\": False}\n",
    "            )\n",
    "            if actual != col:\n",
    "                df = df.rename(columns={actual: col})\n",
    "\n",
    "    # ---- resolve metric columns actually present ----\n",
    "    resolved_numeric = {}\n",
    "    for out_name, col in numeric_metrics.items():\n",
    "        actual = find_column(df, col)\n",
    "        if actual:\n",
    "            resolved_numeric[out_name] = actual\n",
    "        else:\n",
    "            print(\n",
    "                f\"⚠ Warning: column '{col}' not found (case-insensitive) \"\n",
    "                f\"→ skipping '{out_name}'\"\n",
    "            )\n",
    "\n",
    "    resolved_boolean = {}\n",
    "    for out_name, col in bool_metrics.items():\n",
    "        actual = find_column(df, col)\n",
    "        if actual:\n",
    "            resolved_boolean[out_name] = actual\n",
    "        else:\n",
    "            print(\n",
    "                f\"⚠ Warning: column '{col}' not found (case-insensitive) \"\n",
    "                f\"→ skipping '{out_name}'\"\n",
    "            )\n",
    "\n",
    "    g = df.groupby(\"Model\")\n",
    "    agg_parts = {}\n",
    "\n",
    "    # ---- numeric means ----\n",
    "    for out_name, actual_col in resolved_numeric.items():\n",
    "        agg_parts[out_name] = g[actual_col].mean()  # skipna=True by default\n",
    "\n",
    "    # ---- boolean TRUE rate: #True / (#True + #False) ----\n",
    "    for out_name, actual_col in resolved_boolean.items():\n",
    "        true_count = g[actual_col].apply(lambda x: x.eq(True).sum())\n",
    "        tf_count = g[actual_col].apply(lambda x: x.isin([True, False]).sum())\n",
    "        agg_parts[out_name] = true_count / tf_count\n",
    "\n",
    "    summary = pd.concat(agg_parts, axis=1)\n",
    "\n",
    "    # ---- canonicalise index again & merge any accidental duplicates ----\n",
    "    # (e.g., if some model names slipped through differently earlier)\n",
    "    summary.index = (\n",
    "        summary.index.to_series()\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "        .str.upper()\n",
    "    )\n",
    "    summary = summary.groupby(summary.index).mean()\n",
    "\n",
    "    # ---- reorder columns consistently ----\n",
    "    summary = summary[[c for c in ordered_cols if c in summary.columns]]\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def compute_cv(ps_summaries, ps_sheet_names):\n",
    "    \"\"\"\n",
    "    Coefficient of variation across PS1..PS5 for each model & metric.\n",
    "    CV = std / mean, computed over non-empty values, ignoring NaNs.\n",
    "    \"\"\"\n",
    "    # union of models\n",
    "    models = sorted(set().union(*[ps_summaries[s].index for s in ps_sheet_names]))\n",
    "    # union of columns\n",
    "    cols = sorted(set().union(*[ps_summaries[s].columns for s in ps_sheet_names]))\n",
    "\n",
    "    cv_data = {col: [] for col in cols}\n",
    "\n",
    "    for m in models:\n",
    "        for col in cols:\n",
    "            vals = []\n",
    "            for s in ps_sheet_names:\n",
    "                df = ps_summaries[s]\n",
    "                if col in df.columns and m in df.index:\n",
    "                    v = df.at[m, col]\n",
    "                    if pd.notna(v):\n",
    "                        vals.append(float(v))\n",
    "            if len(vals) >= 2 and np.mean(vals) != 0:\n",
    "                vals_series = pd.Series(vals, dtype=float)\n",
    "                cv = vals_series.std(ddof=0) / vals_series.mean()\n",
    "            else:\n",
    "                cv = np.nan\n",
    "            cv_data[col].append(cv)\n",
    "\n",
    "    cv_df = pd.DataFrame(cv_data, index=models)\n",
    "    # order columns like the others\n",
    "    cv_df = cv_df[[c for c in ordered_cols if c in cv_df.columns]]\n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c06623-2e82-49dd-9582-50cb3b2d98fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all sheets\n",
    "book = pd.read_excel(xlsx_path, sheet_name=None, engine=\"openpyxl\")\n",
    "\n",
    "ps_summaries = {}\n",
    "all_rows = []\n",
    "\n",
    "for sheet in ps_sheets:\n",
    "    df = book[sheet]\n",
    "    print(f\"\\nProcessing {sheet} — columns detected:\\n{list(df.columns)}\")\n",
    "    summary = summarize_sheet(df)\n",
    "    ps_summaries[sheet] = summary\n",
    "    all_rows.append(df)\n",
    "\n",
    "# TOTAL summary (mean over all rows that actually have each value)\n",
    "total_df = pd.concat(all_rows, ignore_index=True)\n",
    "ps_summaries[\"Total\"] = summarize_sheet(total_df)\n",
    "\n",
    "# CV summary across PS1..PS5 only\n",
    "cv_summary = compute_cv(ps_summaries, ps_sheets)\n",
    "ps_summaries[\"CV\"] = cv_summary\n",
    "\n",
    "# ---- rounding & percentage formatting ----\n",
    "numeric_cols = set(numeric_metrics.keys())\n",
    "bool_cols = set(bool_metrics.keys())\n",
    "\n",
    "for ps_name, df in ps_summaries.items():\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if ps_name == \"CV\":\n",
    "            # CV as percentage for all metrics\n",
    "            df[col] = (df[col] * 100).round(2)\n",
    "        else:\n",
    "            if col in numeric_cols:\n",
    "                df[col] = df[col].round(2)\n",
    "            elif col in bool_cols:\n",
    "                # convert compliance rates to %\n",
    "                df[col] = (df[col] * 100).round(2)\n",
    "    ps_summaries[ps_name] = df\n",
    "\n",
    "# ---- build Summary sheet blocks ----\n",
    "blocks = []\n",
    "for ps_name in [\"PS1\", \"PS2\", \"PS3\", \"PS4\", \"PS5\", \"Total\", \"CV\"]:\n",
    "    summary = ps_summaries[ps_name]\n",
    "    block = summary.copy()\n",
    "    block.insert(0, \"PS\", ps_name)\n",
    "    block = block.reset_index()  # Model becomes a column named 'index'\n",
    "    block = block.rename(columns={\"index\": \"Model\"})\n",
    "    blocks.append(block)\n",
    "    # separator row\n",
    "    blocks.append(pd.DataFrame([[None] * block.shape[1]], columns=block.columns))\n",
    "\n",
    "summary_sheet = pd.concat(blocks, ignore_index=True)\n",
    "\n",
    "# 1. Start from a copy of your original file (so we don't overwrite it in-place)\n",
    "shutil.copy2(xlsx_path, output_path)\n",
    "\n",
    "# 2. Open the copied workbook with openpyxl\n",
    "wb = load_workbook(output_path)\n",
    "\n",
    "# 3. If a \"Summary\" sheet already exists, remove it\n",
    "if \"Summary\" in wb.sheetnames:\n",
    "    std = wb[\"Summary\"]\n",
    "    wb.remove(std)\n",
    "\n",
    "# 4. Create a fresh Summary sheet\n",
    "ws = wb.create_sheet(\"Summary\")\n",
    "\n",
    "# 5. Dump the pandas DataFrame into the Summary sheet\n",
    "for r_idx, row in enumerate(dataframe_to_rows(summary_sheet, index=False, header=True), start=1):\n",
    "    ws.append(row)\n",
    "\n",
    "# 6. Save the updated workbook\n",
    "wb.save(output_path)\n",
    "\n",
    "print(f\"\\nSummary (with Total + CV) written to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab39b26-ca7a-4103-8696-7b86350092fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fcb87e-495c-41c8-a06b-7b6e07763751",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c89fea-fa6e-4328-bc5d-8876625fb448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
