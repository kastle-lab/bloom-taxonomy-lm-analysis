{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89052804-2e2a-4c09-a8d4-526285a9f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "AEQG Normalization — Notebook (Exact‑Keyword Only)\n",
    "-------------------------------------------------\n",
    "This module is **normalization only** (no metric computation). Use directly in a\n",
    "notebook to convert LLM‑noisy rubric cells into strict canonical labels.\n",
    "\n",
    "Rules:\n",
    "  • Cells may contain extra prose, but the exact label appears somewhere.\n",
    "  • Case‑insensitive; supports minor separator variants (e.g., `more_or_less`).\n",
    "  • Priority when extracting a label from a cell:\n",
    "      1) Explicit final markers:  \"final/overall/decision/verdict: <label>\"\n",
    "      2) Field‑labeled spans:     \"Clear: <label>\", \"WouldYouUseIt=<label>\", etc.\n",
    "      3) Fallback:                **last** canonical token in the cell (word boundaries)\n",
    "  • Strips any `<think>…</think>` or `<think>…<\\think>` blocks before parsing.\n",
    "\n",
    "Canonical columns (order for no‑header CSVs):\n",
    "  0 Understandable | 1 TopicRelated | 2 Grammatical | 3 Clear | 4 Rephrase |\n",
    "  5 Answerable | 6 Central | 7 WouldYouUseIt | 8 Bloom’sLevel\n",
    "\n",
    "Canonical value sets:\n",
    "  • Binary:        {\"yes\",\"no\"}\n",
    "  • Clear:         {\"yes\",\"no\",\"more_or_less\"}\n",
    "  • WouldYouUseIt: {\"yes\",\"maybe\",\"no\"}\n",
    "  • Bloom’sLevel:  {\"remember\",\"understand\",\"apply\",\"analyze\",\"evaluate\",\"create\"}\n",
    "\n",
    "Notebook usage:\n",
    "    raw_df = read_csv_no_header(\"PS1_gemma3:latest.csv\")\n",
    "    clean_df, issues_df = normalize_exact_dataframe(raw_df, has_header=False)\n",
    "    # -> pass clean_df to your metrics code separately\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "from typing import List, Optional, Tuple\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ============================\n",
    "# Canonical schema / constants\n",
    "# ============================\n",
    "COLS = [\n",
    "    \"Understandable\",\n",
    "    \"TopicRelated\",\n",
    "    \"Grammatical\",\n",
    "    \"Clear\",\n",
    "    \"Rephrase\",\n",
    "    \"Answerable\",\n",
    "    \"Central\",\n",
    "    \"WouldYouUseIt\",\n",
    "    \"Bloom’sLevel\",\n",
    "]\n",
    "\n",
    "ALLOWED = {\n",
    "    \"Understandable\": {\"yes\", \"no\"},\n",
    "    \"TopicRelated\": {\"yes\", \"no\"},\n",
    "    \"Grammatical\": {\"yes\", \"no\"},\n",
    "    \"Clear\": {\"yes\", \"no\", \"more_or_less\"},\n",
    "    \"Rephrase\": {\"yes\", \"no\"},\n",
    "    \"Answerable\": {\"yes\", \"no\"},\n",
    "    \"Central\": {\"yes\", \"no\"},\n",
    "    \"WouldYouUseIt\": {\"yes\", \"maybe\", \"no\"},\n",
    "    \"Bloom’sLevel\": {\"remember\", \"understand\", \"apply\", \"analyze\", \"evaluate\", \"create\"},\n",
    "}\n",
    "\n",
    "# ======================\n",
    "# Text + pattern helpers\n",
    "# ======================\n",
    "_THINK_RE = re.compile(r\"<\\s*think\\s*>.*?<\\s*[\\\\/]\\s*think\\s*>\", re.IGNORECASE | re.DOTALL)\n",
    "_WS_RE = re.compile(r\"\\s+\")\n",
    "\n",
    "# exact labels (word boundaries, case‑insensitive)\n",
    "_RX_YES   = re.compile(r\"\\byes\\b\", re.IGNORECASE)\n",
    "_RX_NO    = re.compile(r\"\\bno\\b\", re.IGNORECASE)\n",
    "_RX_MAYBE = re.compile(r\"\\bmaybe\\b\", re.IGNORECASE)\n",
    "\n",
    "# Clear middle state\n",
    "_RX_MOL_SPACE = re.compile(r\"\\bmore\\s+or\\s+less\\b\", re.IGNORECASE)\n",
    "_RX_MOL_DASH  = re.compile(r\"\\bmore-?or-?less\\b\", re.IGNORECASE)   # more-or-less / moreorless\n",
    "_RX_MOL_UND   = re.compile(r\"\\bmore[_ ]or[_ ]less\\b\", re.IGNORECASE)\n",
    "\n",
    "# Bloom (accept UK \"analyse\" → analyze)\n",
    "_BLOOM_RXS: List[Tuple[re.Pattern, str]] = [\n",
    "    (re.compile(r\"\\bremember\\b\", re.IGNORECASE),   \"remember\"),\n",
    "    (re.compile(r\"\\bunderstand\\b\", re.IGNORECASE), \"understand\"),\n",
    "    (re.compile(r\"\\bapply\\b\", re.IGNORECASE),      \"apply\"),\n",
    "    (re.compile(r\"\\banal(?:y|ys|yz)e\\b\", re.IGNORECASE), \"analyze\"),\n",
    "    (re.compile(r\"\\bevaluate\\b\", re.IGNORECASE),   \"evaluate\"),\n",
    "    (re.compile(r\"\\bcreate\\b\", re.IGNORECASE),     \"create\"),\n",
    "]\n",
    "\n",
    "# Field signatures to clip labeled spans (we still extract exact tokens inside)\n",
    "_FIELD_SIGS = {\n",
    "    \"Understandable\": [\"understandable\", \"understand\"],\n",
    "    \"TopicRelated\":   [\"topicrelated\", \"topic\"],\n",
    "    \"Grammatical\":    [\"grammatical\", \"grammar\"],\n",
    "    \"Clear\":          [\"clear\"],\n",
    "    \"Rephrase\":       [\"rephrase\", \"rephrased\", \"reword\"],\n",
    "    \"Answerable\":     [\"answerable\", \"answer\"],\n",
    "    \"Central\":        [\"central\", \"core\"],\n",
    "    \"WouldYouUseIt\":  [\"wouldyouuseit\", \"would_use_it\", \"useit\", \"use\"],\n",
    "    \"Bloom’sLevel\":   [\"bloom\", \"bloomslevel\", \"bloomlevel\", \"level\"],\n",
    "}\n",
    "\n",
    "# generic value snippets used only to bound labeled spans\n",
    "_VAL_YESNO = r\"(yes|no)\\b\"\n",
    "_VAL_MAYBE = r\"(maybe|yes|no)\\b\"\n",
    "_VAL_CLEAR = r\"(more\\s*or\\s*less|yes|no)\\b\"\n",
    "_VAL_BLOOM = r\"(remember|understand|apply|anal(?:y|ys|yz)e|evaluate|create)\\b\"\n",
    "\n",
    "\n",
    "def _strip_think(text: object) -> str:\n",
    "    if text is None or (isinstance(text, float) and pd.isna(text)):\n",
    "        return \"\"\n",
    "    return _THINK_RE.sub(\" \", str(text))\n",
    "\n",
    "\n",
    "def _norm(text: object) -> str:\n",
    "    s = _strip_think(text)\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    s = s.strip().lower()\n",
    "    return _WS_RE.sub(\" \", s)\n",
    "\n",
    "\n",
    "def _find_last_token(t: str, tokens: List[str]) -> Optional[str]:\n",
    "    last_label, last_pos = None, -1\n",
    "    for tok in tokens:\n",
    "        for m in re.finditer(rf\"\\b{re.escape(tok)}\\b\", t, flags=re.IGNORECASE):\n",
    "            if m.start() > last_pos:\n",
    "                last_pos, last_label = m.start(), tok\n",
    "    return last_label\n",
    "\n",
    "\n",
    "def _compile_field_label_regex(field: str, value_regex: str) -> List[re.Pattern]:\n",
    "    rxs: List[re.Pattern] = []\n",
    "    for sig in _FIELD_SIGS[field]:\n",
    "        rxs.append(re.compile(rf\"^(?:\\s*{sig}\\s*[:=-]\\s*{value_regex})\", re.IGNORECASE))\n",
    "        rxs.append(re.compile(rf\"\\b{sig}\\s*[:=-]\\s*{value_regex}\", re.IGNORECASE))\n",
    "    return rxs\n",
    "\n",
    "_RULE2_RXS = {\n",
    "    \"Understandable\": _compile_field_label_regex(\"Understandable\", _VAL_YESNO),\n",
    "    \"TopicRelated\":   _compile_field_label_regex(\"TopicRelated\",   _VAL_YESNO),\n",
    "    \"Grammatical\":    _compile_field_label_regex(\"Grammatical\",    _VAL_YESNO),\n",
    "    \"Clear\":          _compile_field_label_regex(\"Clear\",          _VAL_CLEAR),\n",
    "    \"Rephrase\":       _compile_field_label_regex(\"Rephrase\",       _VAL_YESNO),\n",
    "    \"Answerable\":     _compile_field_label_regex(\"Answerable\",     _VAL_YESNO),\n",
    "    \"Central\":        _compile_field_label_regex(\"Central\",        _VAL_YESNO),\n",
    "    \"WouldYouUseIt\":  _compile_field_label_regex(\"WouldYouUseIt\",  _VAL_MAYBE),\n",
    "    \"Bloom’sLevel\":   _compile_field_label_regex(\"Bloom’sLevel\",   _VAL_BLOOM),\n",
    "}\n",
    "\n",
    "_RULE1_RXS = [\n",
    "    re.compile(r\"\\bfinal(?:\\s*(?:answer|decision|verdict))?\\s*[:=-]\\s*(.+)$\", re.IGNORECASE),\n",
    "    re.compile(r\"\\boverall\\s*(?:answer|decision|verdict)?\\s*[:=-]\\s*(.+)$\", re.IGNORECASE)\n",
    "    # re.compile(r\"\\banswer\\s*[:=-]\\s*\\**([a-z0-9_ -]+)\\**\", re.IGNORECASE),\n",
    "    # re.compile(r\"\\bskilllevel\\s*[:=-]\\s*\\**([a-z0-9_ -]+)\\**\", re.IGNORECASE)\n",
    "]\n",
    "\n",
    "\n",
    "def _first_group(t: str, rx: re.Pattern) -> Optional[str]:\n",
    "    m = rx.search(t)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "# =============================\n",
    "# Column extractors (exact only)\n",
    "# =============================\n",
    "\n",
    "def extract_yes_no_exact(text: str, field: str) -> str:\n",
    "    t = _norm(text)\n",
    "    # Special case: treat bare field-name mentions as \"yes\"\n",
    "    if any(sig == t for sig in _FIELD_SIGS[field]):\n",
    "        return \"yes\"\n",
    "    # 1) explicit final marker → search inside\n",
    "    for rx in _RULE1_RXS:\n",
    "        grp = _first_group(t, rx)\n",
    "        if grp:\n",
    "            sub = _norm(grp)\n",
    "            lab = _find_last_token(sub, [\"yes\", \"no\"])  # last wins\n",
    "            if lab: return lab\n",
    "    # 2) field‑labeled span\n",
    "    for rx in _RULE2_RXS[field]:\n",
    "        m = rx.search(t)\n",
    "        if m:\n",
    "            span = m.group(0)\n",
    "            lab = _find_last_token(span, [\"yes\", \"no\"]) or m.group(m.lastindex)\n",
    "            if lab:\n",
    "                lab = lab.lower()\n",
    "                return \"yes\" if lab.startswith(\"y\") else (\"no\" if lab.startswith(\"n\") else lab)\n",
    "    # 3) fallback: last token in whole text\n",
    "    lab = _find_last_token(t, [\"yes\", \"no\"])  # last wins\n",
    "    return lab if lab else t\n",
    "\n",
    "\n",
    "def extract_clear_exact(text: str) -> str:\n",
    "    t = _norm(text)\n",
    "    # 1) explicit final marker\n",
    "    for rx in _RULE1_RXS:\n",
    "        grp = _first_group(t, rx)\n",
    "        if grp:\n",
    "            sub = _norm(grp)\n",
    "            if _RX_MOL_SPACE.search(sub) or _RX_MOL_DASH.search(sub) or _RX_MOL_UND.search(sub):\n",
    "                return \"more_or_less\"\n",
    "            lab = _find_last_token(sub, [\"yes\", \"no\"])  # last wins\n",
    "            if lab: return lab\n",
    "    # 2) field‑labeled span\n",
    "    for rx in _RULE2_RXS[\"Clear\"]:\n",
    "        m = rx.search(t)\n",
    "        if m:\n",
    "            span = _norm(m.group(0))\n",
    "            if _RX_MOL_SPACE.search(span) or _RX_MOL_DASH.search(span) or _RX_MOL_UND.search(span):\n",
    "                return \"more_or_less\"\n",
    "            lab = _find_last_token(span, [\"yes\", \"no\"]) or m.group(m.lastindex)\n",
    "            if lab:\n",
    "                lab = lab.lower()\n",
    "                if lab.startswith(\"yes\"): return \"yes\"\n",
    "                if lab.startswith(\"no\"):  return \"no\"\n",
    "    # 3) fallback: explicit '\"more_or_less\"' anywhere, else last yes/no\n",
    "    if _RX_MOL_SPACE.search(t) or _RX_MOL_DASH.search(t) or _RX_MOL_UND.search(t):\n",
    "        return \"more_or_less\"\n",
    "    lab = _find_last_token(t, [\"yes\", \"no\"])  # last wins\n",
    "    return lab if lab else t\n",
    "\n",
    "\n",
    "def extract_would_use_exact(text: str) -> str:\n",
    "    t = _norm(text)\n",
    "    # 1) explicit final marker\n",
    "    for rx in _RULE1_RXS:\n",
    "        grp = _first_group(t, rx)\n",
    "        if grp:\n",
    "            sub = _norm(grp)\n",
    "            lab = _find_last_token(sub, [\"maybe\", \"yes\", \"no\"])  # last wins\n",
    "            if lab: return lab\n",
    "    # 2) field‑labeled span\n",
    "    for rx in _RULE2_RXS[\"WouldYouUseIt\"]:\n",
    "        m = rx.search(t)\n",
    "        if m:\n",
    "            span = _norm(m.group(0))\n",
    "            lab = _find_last_token(span, [\"maybe\", \"yes\", \"no\"]) or m.group(m.lastindex)\n",
    "            if lab:\n",
    "                lab = lab.lower()\n",
    "                if lab.startswith(\"may\"): return \"maybe\"\n",
    "                if lab.startswith(\"yes\"): return \"yes\"\n",
    "                if lab.startswith(\"no\"):  return \"no\"\n",
    "    # 3) fallback\n",
    "    lab = _find_last_token(t, [\"maybe\", \"yes\", \"no\"])  # last wins\n",
    "    return lab if lab else t\n",
    "\n",
    "\n",
    "def extract_bloom_exact(text: str) -> str:\n",
    "    t = _norm(text)\n",
    "    # 1) explicit final marker\n",
    "    for rx in _RULE1_RXS:\n",
    "        grp = _first_group(t, rx)\n",
    "        if grp:\n",
    "            sub = _norm(grp)\n",
    "            last_lbl, last_pos = None, -1\n",
    "            for rx2, lbl in _BLOOM_RXS:\n",
    "                for m in rx2.finditer(sub):\n",
    "                    if m.start() > last_pos:\n",
    "                        last_pos, last_lbl = m.start(), lbl\n",
    "            if last_lbl: return last_lbl\n",
    "    # 2) field‑labeled span\n",
    "    for rx in _RULE2_RXS[\"Bloom’sLevel\"]:\n",
    "        m = rx.search(t)\n",
    "        if m:\n",
    "            span = _norm(m.group(0))\n",
    "            last_lbl, last_pos = None, -1\n",
    "            for rx2, lbl in _BLOOM_RXS:\n",
    "                for m2 in rx2.finditer(span):\n",
    "                    if m2.start() > last_pos:\n",
    "                        last_pos, last_lbl = m2.start(), lbl\n",
    "            if last_lbl: return last_lbl\n",
    "    # 3) fallback\n",
    "    last_lbl, last_pos = None, -1\n",
    "    for rx2, lbl in _BLOOM_RXS:\n",
    "        for m in rx2.finditer(t):\n",
    "            if m.start() > last_pos:\n",
    "                last_pos, last_lbl = m.start(), lbl\n",
    "    return last_lbl if last_lbl else t\n",
    "\n",
    "# ======================================\n",
    "# DataFrame‑level normalization (notebook)\n",
    "# ======================================\n",
    "\n",
    "def normalize_exact_dataframe(df: pd.DataFrame, has_header: bool = False) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Normalize AEQG data using **exact** labels only (case/spacing tolerant).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame read from your CSV; if no header, read with header=None first\n",
    "    has_header : set True only if `df` already has the 9 canonical column names\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    clean_df : DataFrame with canonical columns and strict labels\n",
    "    issues_df: DataFrame listing rows/columns that did not reduce to allowed labels\n",
    "    \"\"\"\n",
    "    raw = df.copy()\n",
    "\n",
    "    # If no header: assign canonical order/labels\n",
    "    if not has_header:\n",
    "        if all(isinstance(c, int) for c in raw.columns):\n",
    "            if raw.shape[1] != len(COLS):\n",
    "                raise ValueError(f\"Expected {len(COLS)} columns; got {raw.shape[1]}.\")\n",
    "            raw.columns = COLS\n",
    "        else:\n",
    "            if len(raw.columns) != len(COLS):\n",
    "                raise ValueError(\"Header/DataFrame does not match expected 9 columns.\")\n",
    "            # assume provided header order already matches COLS\n",
    "\n",
    "    # Column‑wise extraction\n",
    "    out = pd.DataFrame(index=raw.index)\n",
    "    out[\"Understandable\"] = raw[\"Understandable\"].map(lambda x: extract_yes_no_exact(x, \"Understandable\"))\n",
    "    out[\"TopicRelated\"]   = raw[\"TopicRelated\"].map(lambda x: extract_yes_no_exact(x, \"TopicRelated\"))\n",
    "    out[\"Grammatical\"]    = raw[\"Grammatical\"].map(lambda x: extract_yes_no_exact(x, \"Grammatical\"))\n",
    "    out[\"Clear\"]          = raw[\"Clear\"].map(extract_clear_exact)\n",
    "    out[\"Rephrase\"]       = raw[\"Rephrase\"].map(lambda x: extract_yes_no_exact(x, \"Rephrase\"))\n",
    "    out[\"Answerable\"]     = raw[\"Answerable\"].map(lambda x: extract_yes_no_exact(x, \"Answerable\"))\n",
    "    out[\"Central\"]        = raw[\"Central\"].map(lambda x: extract_yes_no_exact(x, \"Central\"))\n",
    "    out[\"WouldYouUseIt\"]  = raw[\"WouldYouUseIt\"].map(extract_would_use_exact)\n",
    "    out[\"Bloom’sLevel\"]    = raw[\"Bloom’sLevel\"].map(extract_bloom_exact)\n",
    "\n",
    "    # Validate & collect issues\n",
    "    rows, cols, vals = [], [], []\n",
    "    for col, allowed in ALLOWED.items():\n",
    "        bad = ~out[col].isin(allowed)\n",
    "        for r in out.index[bad].tolist():\n",
    "            rows.append(r); cols.append(col); vals.append(out.at[r, col])\n",
    "    issues = pd.DataFrame({\"row\": rows, \"column\": cols, \"value\": vals})\n",
    "\n",
    "    return out, issues\n",
    "\n",
    "# ============================\n",
    "# Minimal helper for CSV input\n",
    "# ============================\n",
    "\n",
    "def read_csv_no_header(path: str, delimiter: str = \",\", encoding: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"Read a CSV with **no header row** and assign canonical column names (COLS).\"\"\"\n",
    "    df = pd.read_csv(path, header=None, sep=delimiter, encoding=encoding)\n",
    "    if df.shape[1] != len(COLS):\n",
    "        raise ValueError(\n",
    "            f\"Expected {len(COLS)} columns in the CSV (no header). Got {df.shape[1]}.\\n\"\n",
    "            f\"Ensure the file has exactly these columns in order: {COLS}\"\n",
    "        )\n",
    "    df.columns = COLS\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d875bd-4850-4809-a3e1-e4d23ec8eb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------gpt-oss:latest----------------\n",
      "-------------------------------------\n",
      "\n",
      "----------------granite4:latest----------------\n",
      "-------------------------------------\n",
      "\n",
      "----------------mistral-small3.2:latest----------------\n",
      "-------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# models = ['deepseek-r1:14b', 'phi4:latest', 'gemma3:latest', 'phi4-mini:latest', 'llama3.2:latest']\n",
    "models = ['gpt-oss:latest', 'granite4:latest', 'mistral-small3.2:latest']\n",
    "prompts = ['PS1','PS2','PS3','PS4','PS5']\n",
    "output_dir_clean = 'clean_output'\n",
    "output_dir_issues = 'clean_output/issues'\n",
    "for model in models:\n",
    "    print(f\"----------------{model}----------------\")\n",
    "    for prompt in prompts:\n",
    "        raw_df = read_csv_no_header(f\"large_{prompt}_{model}.csv\")\n",
    "        clean_df, issues_df = normalize_exact_dataframe(raw_df, has_header=False)\n",
    "        clean_df_path = os.path.join(output_dir_clean, f'{prompt}_{model}_clean.csv')\n",
    "        clean_df.to_csv(clean_df_path, index=False, header=False)\n",
    "        issues_df_path = os.path.join(output_dir_issues, f'{prompt}_{model}_issues.csv')\n",
    "        issues_df.to_csv(issues_df_path, index=False, header=False)\n",
    "    print(f\"-------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdc305-d179-480a-9106-c440c285e5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b49e19-e280-49bb-a7ca-a481cd9e1f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
