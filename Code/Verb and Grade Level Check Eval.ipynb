{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc6efc-bff3-498f-8919-37977428495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8c469c-8603-4d98-930b-71d13e7a1b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_TRIGGERS = {\n",
    "    \"Remember\": [\"Cite\",\"Define\",\"Describe\",\"Draw\",\"Enumerate\",\"Identify\",\"Index\",\"Indicate\",\"Label\",\"List\",\"Match\",\"Meet\",\"Name\",\n",
    "                 \"Outline\",\"Point\",\"Quote\",\"Read\",\"Recall\",\"Recite\",\"Recognize\",\"Record\",\"Repeat\",\"Reproduce\",\"Review\",\"Select\",\n",
    "                 \"State\",\"Study\",\"Tabulate\",\"Trace\",\"Write\"],\n",
    "    \"Understand\": [\"Add\",\"Approximate\",\"Articulate\",\"Associate\",\"Characterize\",\"Clarify\",\"Classify\",\"Compare\",\"Compute\",\"Contrast\",\n",
    "                   \"Convert\",\"Defend\",\"Describe\",\"Detail\",\"Differentiate\",\"Discuss\",\"Distinguish\",\"Elaborate\",\"Estimate\",\"Example\",\n",
    "                   \"Explain\",\"Express\",\"Extend\",\"Extrapolate\",\"Factor\",\"Generalize\",\"Give\",\"Infer\",\"Interact\",\"Interpolate\", \"Interpret\",\n",
    "                   \"Observe\", \"Paraphrase\", \"Picture graphically\", \"Predict\", \"Review\", \"Rewrite\", \"Subtract\", \"Summarize\",\n",
    "                   \"Translate\", \"Visualize\"],\n",
    "    \"Apply\": [\"Acquire\",\"Adapt\",\"Allocate\",\"Alphabetize\",\"Apply\",\"Ascertain\",\"Assign\",\"Attain\",\"Avoid\",\"Back up\",\"Calculate\",\n",
    "              \"Capture\",\"Change\",\"Classify\",\"Complete\",\"Compute\",\"Construct\",\"Customize\",\"Demonstrate\",\"Depreciate\",\"Derive\",\n",
    "              \"Determine\",\"Diminish\",\"Discover\",\"Draw\",\"Employ\",\"Examine\",\"Exercise\",\"Explore\",\"Expose\",\"Express\", \"Factor\", \"Figure\",\n",
    "             \"Graph\", \"Handle\", \"Illustrate\", \"Interconvert\", \"Investigate\",\"Manipulate\",\"Modify\", \"Operate\", \"Personalize\",\n",
    "              \"Plot\",\"Practice\", \"Predict\", \"Prepare\", \"Price\", \"Process\", \"Produce\", \"Project\", \"Provide\", \"Relate\", \"Round off\",\n",
    "             \"Sequence\", \"Show\", \"Simulate\", \"Sketch\", \"Solve\", \"Subscribe\", \"Tabulate\", \"Transcribe\", \"Translate\", \"Use\"],\n",
    "    \"Analyze\": [\"Analyze\",\"Audit\",\"Blueprint\",\"Breadboard\",\"Break down\",\"Characterize\",\"Classify\",\"Compare\",\"Confirm\",\"Contrast\",\n",
    "                \"Correlate\",\"Detect\",\"Diagnose\",\"Diagram\",\"Differentiate\",\"Discriminate\",\"Dissect\",\"Distinguish\",\"Document\",\n",
    "                \"Ensure\",\"Examine\",\"Explain\",\"Explore\",\"Figure out\",\"File\",\"Group\",\"Identify\",\"Illustrate\",\"Infer\",\"Interrupt\",\n",
    "                \"Inventory\", \"Investigate\", \"Layout\", \"Manage\", \"Maximize\", \"Minimize\", \"Optimize\", \"Order\", \"Outline\", \"Point out\",\n",
    "                \"Prioritize\", \"Proofread\", \"Query\", \"Relate\", \"Select\", \"Separate\", \"Subdivide\", \"Train\", \"Transform\"],\n",
    "    \"Evaluate\": [\"Appraise\",\"Assess\",\"Compare\",\"Conclude\",\"Contrast\",\"Counsel\",\"Criticize\",\"Critique\",\"Defend\",\"Determine\",\n",
    "                 \"Discriminate\",\"Estimate\",\"Evaluate\",\"Explain\",\"Grade\",\"Hire\",\"Interpret\",\"Judge\",\"Justify\",\"Measure\",\"Predict\",\n",
    "                 \"Prescribe\",\"Rank\",\"Rate\",\"Recommend\",\"Release\",\"Select\",\"Summarize\",\"Support\",\"Test\",\"Validate\",\"Verify\"],\n",
    "    \"Create\": [\"Abstract\",\"Animate\",\"Arrange\",\"Assemble\",\"Budget\",\"Categorize\",\"Code\",\"Combine\",\"Compile\",\"Compose\",\"Construct\",\n",
    "               \"Cope\",\"Correspond\",\"Create\",\"Cultivate\",\"Debug\",\"Depict\",\"Design\",\"Develop\",\"Devise\",\"Dictate\",\"Enhance\",\n",
    "               \"Explain\",\"Facilitate\",\"Format\",\"Formulate\",\"Generalize\",\"Generate\",\"Handle\",\"Import\",\"Improve\",\"Incorporate\",\n",
    "               \"Integrate\",\"Interface\",\"Join\",\"Lecture\",\"Model\",\"Modify\",\"Network\",\"Organize\",\"Outline\",\"Overhaul\",\"Plan\",\n",
    "               \"Portray\",\"Prepare\",\"Prescribe\",\"Produce\",\"Program\",\"Rearrange\",\"Reconstruct\",\"Relate\",\"Reorganize\",\"Revise\",\n",
    "               \"Rewrite\",\"Specify\",\"Summarize\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fd8e06-cbc5-443f-9a82-cda4896167ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bloom_classifier_datadriven_v2.py\n",
    "from __future__ import annotations\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import math\n",
    "\n",
    "\n",
    "# ---------------------- Config (generic, not per-verb or priority-based) ----------------------\n",
    "# When exact evidence is weak, we blend with semantic similarity instead of discarding exact.\n",
    "BLEND_THRESHOLD = 0.30           # if max exact < this → blend exact + semantic\n",
    "BLEND_ALPHA = 0.45               # final = alpha*Exact(norm) + (1-alpha)*Semantic(norm)\n",
    "\n",
    "# Ambiguity penalty: 1 / (k ** P) where k=#levels containing that lemma/phrase\n",
    "AMBIGUITY_POWER = 1.75            # was 2.0; relax so ambiguous verbs still contribute some signal\n",
    "\n",
    "# Generic attenuation for non-root matches (no per-verb rules)\n",
    "SINGLE_NONROOT_MULT = 0.30       # single-word trigger not at sentence root is weak\n",
    "PHRASE_NONROOT_MULT = 0.70       # multi-word phrase not containing root is moderately weak\n",
    "\n",
    "# ---------------------- NLP setup: prefer Sentence-Transformers, else spaCy vectors ----------------------\n",
    "EMBEDDING_BACKEND = None\n",
    "_embed_model = None\n",
    "_spacy_nlp = None\n",
    "\n",
    "def _try_sentence_transformers():\n",
    "    global EMBEDDING_BACKEND, _embed_model\n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        _embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        EMBEDDING_BACKEND = \"st\"\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _try_spacy_vectors():\n",
    "    global EMBEDDING_BACKEND, _spacy_nlp\n",
    "    try:\n",
    "        import spacy\n",
    "        for name in (\"en_core_web_md\", \"en_core_web_lg\", \"en_core_web_trf\", \"en_core_web_sm\"):\n",
    "            try:\n",
    "                nlp = spacy.load(name)\n",
    "                _spacy_nlp = nlp\n",
    "                if nlp.vocab.vectors:  # real vectors\n",
    "                    EMBEDDING_BACKEND = \"spacy\"\n",
    "                    return True\n",
    "            except Exception:\n",
    "                continue\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _ensure_spacy_for_lemmas():\n",
    "    global _spacy_nlp\n",
    "    if _spacy_nlp is not None:\n",
    "        return True\n",
    "    try:\n",
    "        import spacy\n",
    "        _spacy_nlp = spacy.load(\"en_core_web_sm\")\n",
    "        return True\n",
    "    except Exception:\n",
    "        try:\n",
    "            import spacy\n",
    "            _spacy_nlp = spacy.blank(\"en\")\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "def setup_nlp():\n",
    "    if _try_sentence_transformers():\n",
    "        _ensure_spacy_for_lemmas(); return\n",
    "    if _try_spacy_vectors():\n",
    "        return\n",
    "    _ensure_spacy_for_lemmas()\n",
    "\n",
    "# ---------------------- Lemmatization utils ----------------------\n",
    "WS = re.compile(r\"\\s+\")\n",
    "PUNCT = re.compile(r\"[^\\w\\s'-]\")\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return WS.sub(\" \", PUNCT.sub(\" \", s.strip())).strip()\n",
    "\n",
    "def _lemmas(text: str) -> List[str]:\n",
    "    if _spacy_nlp is None:\n",
    "        return _norm(text).lower().split()\n",
    "    doc = _spacy_nlp(text)\n",
    "    return [t.lemma_.lower() if getattr(t, \"lemma_\", None) else t.text.lower()\n",
    "            for t in doc if t.text.strip()]\n",
    "\n",
    "def _lemma_tuple(phrase: str) -> Tuple[str, ...]:\n",
    "    return tuple(_lemmas(phrase))\n",
    "\n",
    "# ---------------------- Build indices (data-only) ----------------------\n",
    "def build_trigger_index(raw: Dict[str, List[str]]):\n",
    "    level_to_phrases = {}\n",
    "    level_to_lemmas = {}\n",
    "    singles, multis = {}, {}\n",
    "    for level, phrases in raw.items():\n",
    "        uniq = []\n",
    "        seen = set()\n",
    "        for p in phrases:\n",
    "            if not p or not p.strip():\n",
    "                continue\n",
    "            pn = _norm(p)\n",
    "            if pn not in seen:\n",
    "                seen.add(pn); uniq.append(pn)\n",
    "        level_to_phrases[level] = uniq\n",
    "        ltuples = [_lemma_tuple(p) for p in uniq]\n",
    "        level_to_lemmas[level] = ltuples\n",
    "        singles[level] = set(w[0] for w in ltuples if len(w) == 1)\n",
    "        multis[level]  = set(w for w in ltuples if len(w) > 1)\n",
    "    return level_to_phrases, level_to_lemmas, singles, multis\n",
    "\n",
    "def build_conflict_index(level_to_lemmas: Dict[str, List[Tuple[str,...]]]):\n",
    "    lemma_levels = defaultdict(set)\n",
    "    phrase_levels = defaultdict(set)\n",
    "    for lvl, tuples in level_to_lemmas.items():\n",
    "        for t in tuples:\n",
    "            if len(t) == 1:\n",
    "                lemma_levels[t[0]].add(lvl)\n",
    "            elif len(t) > 1:\n",
    "                phrase_levels[t].add(lvl)\n",
    "    lemma_counts  = {lem: len(lvls) for lem, lvls in lemma_levels.items()}\n",
    "    phrase_counts = {phr: len(lvls) for phr, lvls in phrase_levels.items()}\n",
    "    return lemma_counts, phrase_counts\n",
    "\n",
    "# ---------------------- Exact matching (conflict-aware + root sensitivity) ----------------------\n",
    "def _find_doc_root(doc):\n",
    "    try:\n",
    "        return next((t for t in doc if t.head == t), None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def exact_match_scores(question: str,\n",
    "                       singles: Dict[str,set],\n",
    "                       multis: Dict[str,set],\n",
    "                       lemma_counts: Dict[str,int],\n",
    "                       phrase_counts: Dict[Tuple[str,...],int],\n",
    "                       spacy_nlp) -> Tuple[Dict[str,float], int]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        scores: dict[level] -> float\n",
    "        hit_count: number of distinct trigger hits (singles+phrases) found anywhere\n",
    "    \"\"\"\n",
    "    doc = spacy_nlp(question)\n",
    "    toks = [t.lemma_.lower() if getattr(t, \"lemma_\", None) else t.text.lower() for t in doc]\n",
    "    uni = set(toks)\n",
    "    root = _find_doc_root(doc)\n",
    "    root_lem = root.lemma_.lower() if (root is not None and hasattr(root, \"lemma_\")) else None\n",
    "\n",
    "    def weight_single(lem: str) -> float:\n",
    "        k = max(1, lemma_counts.get(lem, 1))\n",
    "        base = 1.0 / float(k ** AMBIGUITY_POWER)     # softer than k^2 but penalizes ambiguity\n",
    "        mult = 1.0 if (root_lem is not None and lem == root_lem) else SINGLE_NONROOT_MULT\n",
    "        return base * mult\n",
    "\n",
    "    def weight_phrase(tup: Tuple[str,...]) -> float:\n",
    "        k = max(1, phrase_counts.get(tup, 1))\n",
    "        base = 2.0 / float(k ** AMBIGUITY_POWER)\n",
    "        contains_root = (root_lem is not None and root_lem in tup)\n",
    "        mult = 1.0 if contains_root else PHRASE_NONROOT_MULT\n",
    "        return base * mult\n",
    "\n",
    "    def ngrams(seq: List[str], n: int):\n",
    "        return {tuple(seq[i:i+n]) for i in range(0, max(0, len(seq)-n+1))}\n",
    "\n",
    "    max_len = max((len(p) for s in multis.values() for p in s), default=1)\n",
    "    ngram_bags = {n: ngrams(toks, n) for n in range(2, max_len+1)}\n",
    "\n",
    "    scores = defaultdict(float)\n",
    "    hit_count = 0\n",
    "\n",
    "    # singles\n",
    "    for level, vocab in singles.items():\n",
    "        hits = uni & vocab\n",
    "        for lem in hits:\n",
    "            scores[level] += weight_single(lem)\n",
    "            hit_count += 1\n",
    "\n",
    "    # phrases\n",
    "    for level, phrases in multis.items():\n",
    "        for phr in phrases:\n",
    "            n = len(phr)\n",
    "            if phr in ngram_bags.get(n, set()):\n",
    "                scores[level] += weight_phrase(phr)\n",
    "                hit_count += 1\n",
    "\n",
    "    return dict(scores), hit_count\n",
    "\n",
    "# ---------------------- Semantic similarity (data-only) ----------------------\n",
    "_embed_cache_ready = False\n",
    "_flat_triggers: List[Tuple[str, str]] = []  # [(level, phrase)]\n",
    "_flat_trigger_vecs = None\n",
    "\n",
    "def _prepare_trigger_embeddings(level_to_phrases: Dict[str,List[str]]):\n",
    "    global _embed_cache_ready, _flat_triggers, _flat_trigger_vecs\n",
    "    if _embed_cache_ready:\n",
    "        return\n",
    "    _flat_triggers = [(lvl, p) for lvl, lst in level_to_phrases.items() for p in lst]\n",
    "    P = _embed_texts([p for _, p in _flat_triggers])\n",
    "    _flat_trigger_vecs = P\n",
    "    _embed_cache_ready = True\n",
    "\n",
    "def _embed_texts(texts: List[str]):\n",
    "    global EMBEDDING_BACKEND, _embed_model, _spacy_nlp\n",
    "    if EMBEDDING_BACKEND == \"st\":\n",
    "        return _embed_model.encode(texts, normalize_embeddings=True)\n",
    "    if EMBEDDING_BACKEND == \"spacy\" and _spacy_nlp is not None and _spacy_nlp.vocab.vectors:\n",
    "        import numpy as np\n",
    "        vecs = []\n",
    "        for t in texts:\n",
    "            doc = _spacy_nlp(t)\n",
    "            v = doc.vector\n",
    "            n = float(np.linalg.norm(v))\n",
    "            vecs.append(v / n if n > 0 else v)\n",
    "        return vecs\n",
    "    return None\n",
    "\n",
    "def _cos(a, b):\n",
    "    try:\n",
    "        import numpy as np\n",
    "        return float(np.dot(a, b))\n",
    "    except Exception:\n",
    "        return float(sum(x*y for x, y in zip(a, b)))\n",
    "\n",
    "def semantic_scores(question: str,\n",
    "                    level_to_phrases: Dict[str,List[str]]) -> Optional[Dict[str, float]]:\n",
    "    _prepare_trigger_embeddings(level_to_phrases)\n",
    "    if _flat_trigger_vecs is None:\n",
    "        return None\n",
    "    Q = _embed_texts([question])\n",
    "    if Q is None:\n",
    "        return None\n",
    "    qv = Q[0]\n",
    "    per_level = defaultdict(float)  # take MAX similarity per level\n",
    "    for (lvl, _p), vec in zip(_flat_triggers, _flat_trigger_vecs):\n",
    "        sim = _cos(qv, vec)\n",
    "        if sim > per_level[lvl]:\n",
    "            per_level[lvl] = sim\n",
    "    return dict(per_level)\n",
    "\n",
    "# ---------------------- Last-resort: lemma Jaccard (data-only) ----------------------\n",
    "def lemma_overlap_scores(question: str, level_to_lemmas: Dict[str, List[Tuple[str,...]]]) -> Dict[str, float]:\n",
    "    qset = set(_lemma_tuple(question))\n",
    "    scores = {}\n",
    "    for lvl, ltuples in level_to_lemmas.items():\n",
    "        best = 0.0\n",
    "        for tup in ltuples:\n",
    "            pset = set(tup)\n",
    "            if not pset:\n",
    "                continue\n",
    "            inter = len(qset & pset)\n",
    "            uni = len(qset | pset)\n",
    "            best = max(best, (inter / uni) if uni else 0.0)\n",
    "        scores[lvl] = best\n",
    "    return scores\n",
    "\n",
    "# ---------------------- Score utilities ----------------------\n",
    "def _normalize(scores: Dict[str, float]) -> Dict[str, float]:\n",
    "    if not scores:\n",
    "        return scores\n",
    "    mx = max(scores.values())\n",
    "    if mx <= 0:\n",
    "        # avoid all-zero; return as-is\n",
    "        return scores\n",
    "    return {k: (v / mx) for k, v in scores.items()}\n",
    "\n",
    "def _rank(scores: Dict[str, float]):\n",
    "    return sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "# ---------------------- Public Classifier ----------------------\n",
    "class BloomClassifier:\n",
    "    def __init__(self):\n",
    "        setup_nlp()\n",
    "        (self.level_to_phrases,\n",
    "         self.level_to_lemmas,\n",
    "         self.singles,\n",
    "         self.multis) = build_trigger_index(RAW_TRIGGERS)\n",
    "        self.lemma_counts, self.phrase_counts = build_conflict_index(self.level_to_lemmas)\n",
    "        _prepare_trigger_embeddings(self.level_to_phrases)\n",
    "\n",
    "    def classify(self, question: str, top_k: int = 3):\n",
    "        # 1) exact (conflict-aware + root sensitivity)\n",
    "        exact, hit_count = exact_match_scores(\n",
    "            question,\n",
    "            self.singles, self.multis,\n",
    "            self.lemma_counts, self.phrase_counts,\n",
    "            _spacy_nlp\n",
    "        )\n",
    "\n",
    "        method = None\n",
    "        scores = {}\n",
    "\n",
    "        if exact:\n",
    "            # strong enough? keep exact as-is\n",
    "            if max(exact.values()) >= BLEND_THRESHOLD or hit_count >= 2:\n",
    "                scores = exact\n",
    "                method = \"exact\"\n",
    "            else:\n",
    "                # weak exact → try blending with semantic if available\n",
    "                sem = semantic_scores(question, self.level_to_phrases)\n",
    "                if sem:\n",
    "                    exact_n = _normalize(exact)\n",
    "                    sem_n = _normalize(sem)\n",
    "                    # blend\n",
    "                    scores = {lvl: BLEND_ALPHA * exact_n.get(lvl, 0.0) + (1.0 - BLEND_ALPHA) * sem_n.get(lvl, 0.0)\n",
    "                              for lvl in set(exact_n) | set(sem_n)}\n",
    "                    method = \"blend\"\n",
    "                else:\n",
    "                    # no embeddings → fall back to lemma overlap, but still incorporate exact (normalized)\n",
    "                    jacc = lemma_overlap_scores(question, self.level_to_lemmas)\n",
    "                    exact_n = _normalize(exact)\n",
    "                    jacc_n = _normalize(jacc)\n",
    "                    scores = {lvl: BLEND_ALPHA * exact_n.get(lvl, 0.0) + (1.0 - BLEND_ALPHA) * jacc_n.get(lvl, 0.0)\n",
    "                              for lvl in set(exact_n) | set(jacc_n)}\n",
    "                    method = \"blend_lemma\"\n",
    "        else:\n",
    "            # 2) no exact → semantic; else lemma-overlap\n",
    "            sem = semantic_scores(question, self.level_to_phrases)\n",
    "            if sem:\n",
    "                scores = sem\n",
    "                method = \"semantic\"\n",
    "            else:\n",
    "                scores = lemma_overlap_scores(question, self.level_to_lemmas)\n",
    "                method = \"lemma_overlap\"\n",
    "\n",
    "        ranked = _rank(scores)\n",
    "        decided_level, decided_score = ranked[0]\n",
    "        ties = [lvl for lvl, sc in ranked if math.isclose(sc, decided_score, rel_tol=1e-6, abs_tol=1e-9)]\n",
    "\n",
    "        return {\n",
    "            \"method\": method,\n",
    "            \"decided\": decided_level if len(ties) == 1 else None,  # None if tie at top\n",
    "            \"top_levels\": ranked[:top_k],\n",
    "            \"ties_at_top\": ties if len(ties) > 1 else [],\n",
    "            \"all_scores\": scores\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648123d3-a714-4760-8f02-a586159d3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- Demo ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    clf = BloomClassifier()\n",
    "    tests = [\n",
    "        \"List the steps of the Krebs cycle.\",\n",
    "        \"How would you explain the trade-offs of this design?\",\n",
    "        \"Calculate the standard deviation of this dataset.\",\n",
    "        \"Compare A vs B and justify your choice.\",\n",
    "        \"Break down the factors that influence demand.\",\n",
    "        \"Design an experiment to test plant growth.\",\n",
    "        \"What are the ethical implications of using facial recognition in schools?\"\n",
    "    ]\n",
    "    for q in tests:\n",
    "        r = clf.classify(q)\n",
    "        print(f\"\\nQ: {q}\\n -> method={r['method']} | decided={r['decided']} | top={[(k, round(v, 3)) for k, v in r['top_levels']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c809b-8abd-421e-8436-1ce3bb9ed053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bloom_lemmatizer_match.py\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "l_n = {(int(index)+1):key for index,key in enumerate(RAW_TRIGGERS.keys())}\n",
    "# ---------------- Setup spaCy for lemmatization ----------------\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    import spacy.cli\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def normalize(text: str) -> str:\n",
    "    \"\"\"Strip punctuation and lowercase text.\"\"\"\n",
    "    return re.sub(r\"[^\\w\\s'-]\", \"\", text).strip().lower()\n",
    "\n",
    "def lemmatize(text: str) -> list[str]:\n",
    "    \"\"\"Return lemmatized tokens using spaCy.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [t.lemma_.lower() for t in doc if t.text.strip()]\n",
    "\n",
    "# ---------------- Build lemma lookup ----------------\n",
    "LEVEL_TO_LEMMAS = {}\n",
    "for level, verbs in RAW_TRIGGERS.items():\n",
    "    lemmas = set()\n",
    "    for v in verbs:\n",
    "        for l in lemmatize(normalize(v)):\n",
    "            lemmas.add(l)\n",
    "    LEVEL_TO_LEMMAS[level] = lemmas\n",
    "\n",
    "# ---------------- Classification ----------------\n",
    "def classify_question(question: str):\n",
    "    q_lemmas = set(lemmatize(question))\n",
    "    scores = defaultdict(int)\n",
    "\n",
    "    for level, lemmas in LEVEL_TO_LEMMAS.items():\n",
    "        overlap = q_lemmas & lemmas\n",
    "        scores[level] = len(overlap)\n",
    "\n",
    "    # sort by matches\n",
    "    ranked = sorted(scores.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    best_level, best_score = ranked[0]\n",
    "\n",
    "    # If no match at all, return None\n",
    "    decided = best_level if best_score > 0 else None\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"decided\": decided,\n",
    "        \"scores\": ranked\n",
    "    }\n",
    "def check_if_assigned_correct_level(question,level):\n",
    "    # Ensure the question is a string, and handle missing values\n",
    "    if not isinstance(question, str):\n",
    "        question = str(question) if question is not None else \"\"\n",
    "        \n",
    "    result = classify_question(question)\n",
    "    possibilities = [item[0].lower().strip() for item in result['scores'] if item[1] != 0]\n",
    "    \n",
    "    return l_n[level].lower().strip() in possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374c2d32-a15a-4c09-9d3d-e49c0ac7b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    \"List the steps of the Krebs cycle.\",\n",
    "    \"How would you explain the trade-offs of this design?\",\n",
    "    \"Calculate the standard deviation of this dataset.\",\n",
    "    \"Compare A vs B and justify your choice.\",\n",
    "    \"Break down the factors that influence demand.\",\n",
    "    \"Design an experiment to test plant growth.\",\n",
    "    \"What are the ethical implications of using facial recognition in schools?\"\n",
    "]\n",
    "\n",
    "for q in tests:\n",
    "    # r = classify_question(q)\n",
    "    # print(f\"\\nQ: {q}\\n -> decided={r['decided']} | scores={r['scores']}\")\n",
    "    print(check_if_assigned_correct_level(q,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6dd2cf-0be2-4b36-93e1-c2ba78b796f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b40c94-dec4-4703-868f-4f221069e8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "def questions_level_eval(og_excel, mod_excel):\n",
    "    wb = load_workbook(og_excel)\n",
    "    ps_sheets = [sheet for sheet in wb.sheetnames if sheet.startswith('PS')]\n",
    "    modified_dfs = {}\n",
    "\n",
    "    for sheet_name in ps_sheets:\n",
    "        df = pd.read_excel(og_excel, sheet_name=sheet_name)\n",
    "        results = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            question = row['Questions']\n",
    "            level = row['Index'] % 6 or 6\n",
    "            result = check_if_assigned_correct_level(question, level)\n",
    "            results.append(result)\n",
    "\n",
    "        # Insert at index 4 (fifth column)\n",
    "        df.insert(4, 'Assigned Level Check', results)\n",
    "        modified_dfs[sheet_name] = df\n",
    "\n",
    "    with pd.ExcelWriter(mod_excel, engine='openpyxl') as writer:\n",
    "        for sheet_name, modified_df in modified_dfs.items():\n",
    "            modified_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            ws = writer.sheets[sheet_name]\n",
    "            original_ws = wb[sheet_name]\n",
    "\n",
    "            # shift merged ranges if they are at/after column 5 (E)\n",
    "            shift_index = 5\n",
    "            for merged_range in original_ws.merged_cells.ranges:\n",
    "                start_col, start_row, end_col, end_row = merged_range.bounds\n",
    "\n",
    "                if start_col >= shift_index:\n",
    "                    start_col += 1\n",
    "                    end_col += 1\n",
    "\n",
    "                new_range = f\"{get_column_letter(start_col)}{start_row}:{get_column_letter(end_col)}{end_row}\"\n",
    "                ws.merge_cells(new_range)\n",
    "\n",
    "        # === Copy Summary sheet \"as is\" ===\n",
    "        if \"Summary\" in wb.sheetnames:\n",
    "            orig_summary = wb[\"Summary\"]\n",
    "            new_summary = writer.book.create_sheet(\"Summary\")\n",
    "\n",
    "            for row in orig_summary.iter_rows():\n",
    "                for cell in row:\n",
    "                    new_cell = new_summary.cell(row=cell.row, column=cell.col_idx, value=cell.value)\n",
    "                    if cell.has_style:\n",
    "                        new_cell.font = copy(cell.font)\n",
    "                        new_cell.border = copy(cell.border)\n",
    "                        new_cell.fill = copy(cell.fill)\n",
    "                        new_cell.number_format = copy(cell.number_format)\n",
    "                        new_cell.protection = copy(cell.protection)\n",
    "                        new_cell.alignment = copy(cell.alignment)\n",
    "\n",
    "            # copy column widths\n",
    "            for col_letter, dim in orig_summary.column_dimensions.items():\n",
    "                new_summary.column_dimensions[col_letter].width = dim.width\n",
    "\n",
    "            # copy row heights\n",
    "            for row_idx, dim in orig_summary.row_dimensions.items():\n",
    "                new_summary.row_dimensions[row_idx].height = dim.height\n",
    "\n",
    "            # copy merged cells\n",
    "            for merged_range in orig_summary.merged_cells.ranges:\n",
    "                new_summary.merge_cells(str(merged_range))\n",
    "\n",
    "    print(f\"File saved successfully with merged cells as {mod_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73462800-e643-458c-8e49-4924a87cca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import copy\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter, column_index_from_string\n",
    "\n",
    "def grade_level_eval(og_excel, mod_excel, threshold=15):\n",
    "    wb = load_workbook(og_excel)\n",
    "    ps_sheets = [s for s in wb.sheetnames if s.startswith('PS')]\n",
    "\n",
    "    # prepare modified dataframes for PS2–PS5\n",
    "    modified_dfs = {}\n",
    "    for sheet_name in [\"PS2\", \"PS3\", \"PS4\", \"PS5\"]:\n",
    "        if sheet_name in wb.sheetnames:\n",
    "            df = pd.read_excel(og_excel, sheet_name=sheet_name)\n",
    "            # prefer the named column, otherwise use 6th column\n",
    "            if 'Grade level' in df.columns:\n",
    "                grades = pd.to_numeric(df['Grade level'], errors='coerce')\n",
    "            else:\n",
    "                grades = pd.to_numeric(df.iloc[:, 5], errors='coerce')\n",
    "            results = (grades >= threshold).fillna(False)\n",
    "            df.insert(6, f'Grade Level Check', results.tolist())\n",
    "            modified_dfs[sheet_name] = df\n",
    "\n",
    "    with pd.ExcelWriter(mod_excel, engine='openpyxl') as writer:\n",
    "        # write sheets in the SAME order as the original workbook\n",
    "        for sheet_name in wb.sheetnames:\n",
    "            orig_ws = wb[sheet_name]\n",
    "\n",
    "            if sheet_name in modified_dfs:\n",
    "                # write modified version\n",
    "                modified_df = modified_dfs[sheet_name]\n",
    "                modified_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "                new_ws = writer.sheets[sheet_name]\n",
    "\n",
    "                shift_index = 7  # inserted at col 7\n",
    "                # copy col widths\n",
    "                for col_letter, dim in orig_ws.column_dimensions.items():\n",
    "                    try:\n",
    "                        col_idx = column_index_from_string(col_letter)\n",
    "                    except Exception:\n",
    "                        continue\n",
    "                    new_col_idx = col_idx + 1 if col_idx >= shift_index else col_idx\n",
    "                    new_col_letter = get_column_letter(new_col_idx)\n",
    "                    if dim.width is not None:\n",
    "                        new_ws.column_dimensions[new_col_letter].width = dim.width\n",
    "\n",
    "                # row heights\n",
    "                for row_idx, dim in orig_ws.row_dimensions.items():\n",
    "                    if dim.height is not None:\n",
    "                        new_ws.row_dimensions[row_idx].height = dim.height\n",
    "\n",
    "                # merged ranges adjusted\n",
    "                for merged_range in orig_ws.merged_cells.ranges:\n",
    "                    start_col, start_row, end_col, end_row = merged_range.bounds\n",
    "                    if end_col >= shift_index:\n",
    "                        if start_col >= shift_index:\n",
    "                            start_col += 1\n",
    "                        end_col += 1\n",
    "                    new_range = f\"{get_column_letter(start_col)}{start_row}:{get_column_letter(end_col)}{end_row}\"\n",
    "                    try:\n",
    "                        new_ws.merge_cells(new_range)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "            else:\n",
    "                # copy completely as-is (PS1, Summary, etc.)\n",
    "                new_ws = writer.book.create_sheet(sheet_name)\n",
    "                writer.sheets[sheet_name] = new_ws\n",
    "\n",
    "                max_row = orig_ws.max_row\n",
    "                max_col = orig_ws.max_column\n",
    "                for r in range(1, max_row + 1):\n",
    "                    for c in range(1, max_col + 1):\n",
    "                        source_cell = orig_ws.cell(row=r, column=c)\n",
    "                        new_cell = new_ws.cell(row=r, column=c, value=source_cell.value)\n",
    "                        if getattr(source_cell, \"has_style\", False):\n",
    "                            try:\n",
    "                                new_cell.font = copy(source_cell.font)\n",
    "                                new_cell.border = copy(source_cell.border)\n",
    "                                new_cell.fill = copy(source_cell.fill)\n",
    "                                new_cell.number_format = copy(source_cell.number_format)\n",
    "                                new_cell.protection = copy(source_cell.protection)\n",
    "                                new_cell.alignment = copy(source_cell.alignment)\n",
    "                            except Exception:\n",
    "                                pass\n",
    "\n",
    "                # column widths\n",
    "                for col_letter, dim in orig_ws.column_dimensions.items():\n",
    "                    if dim.width is not None:\n",
    "                        new_ws.column_dimensions[col_letter].width = dim.width\n",
    "                # row heights\n",
    "                for row_idx, dim in orig_ws.row_dimensions.items():\n",
    "                    if dim.height is not None:\n",
    "                        new_ws.row_dimensions[row_idx].height = dim.height\n",
    "                # merged cells\n",
    "                for merged_range in orig_ws.merged_cells.ranges:\n",
    "                    try:\n",
    "                        new_ws.merge_cells(str(merged_range))\n",
    "                    except Exception:\n",
    "                        pass\n",
    "\n",
    "        # remove the default \"Sheet\" if it exists and is empty\n",
    "        if 'Sheet' in writer.book.sheetnames and len(writer.book.sheetnames) > 1:\n",
    "            maybe = writer.book['Sheet']\n",
    "            if maybe.max_row == 1 and maybe.max_column == 1 and maybe.cell(1, 1).value is None:\n",
    "                writer.book.remove(maybe)\n",
    "\n",
    "    print(f\"File saved successfully as {mod_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44896822-0e9f-46e1-bcb6-8d1d4e822fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function for Excel file\n",
    "file_name = \"Large_Model_Questions_WITH_BERTSCORE_PRF_debertaxlargemnli.xlsx\"\n",
    "questions_level_eval(file_name, f\"{file_name.split('.')[-2]}-LevelCheck.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020b499-3d9f-421a-abc6-976bd765305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run for both files\n",
    "grade_level_eval(f\"{file_name.split('.')[-2]}-LevelCheck.xlsx\", f\"{file_name.split('.')[-2]}-BloomAndGradeLevelsCheck.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a85c1b-4aa7-44a3-a074-cf159897594b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
