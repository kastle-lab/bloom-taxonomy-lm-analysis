{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd84858-f33b-42a2-9771-eb43a65cd291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1df190e7-861a-45b9-98b4-c039a88a4dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Large Model Questions.xlsx\n",
      "--------------------------------------------------\n",
      "PS1\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.912719\n",
      "Llama2_70B    0.908100\n",
      "GPT4          0.895762\n",
      "Palm2         0.893064\n",
      "GPT3.5        0.892267\n",
      "Name: sim_1_2, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.892200\n",
      "GPT4          0.889645\n",
      "Llama2_70B    0.884530\n",
      "GPT3.5        0.870746\n",
      "Palm2         0.870107\n",
      "Name: sim_1_3, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.898852\n",
      "Llama2_70B    0.892920\n",
      "GPT4          0.886239\n",
      "Palm2         0.871303\n",
      "GPT3.5        0.868638\n",
      "Name: sim_1_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.894294\n",
      "Mistral_7B    0.893972\n",
      "Llama2_70B    0.892366\n",
      "GPT3.5        0.874869\n",
      "GPT4          0.869723\n",
      "Name: sim_1_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Llama2_70B    0.880172\n",
      "Mistral_7B    0.877864\n",
      "GPT4          0.871640\n",
      "GPT3.5        0.864536\n",
      "Palm2         0.855255\n",
      "Name: sim_1_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.899419\n",
      "Palm2         0.890346\n",
      "Llama2_70B    0.887645\n",
      "GPT4          0.885918\n",
      "GPT3.5        0.877330\n",
      "Name: sim_2_3, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.908890\n",
      "Palm2         0.900217\n",
      "GPT4          0.888066\n",
      "Llama2_70B    0.887596\n",
      "GPT3.5        0.876698\n",
      "Name: sim_2_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.910744\n",
      "Palm2         0.903999\n",
      "Llama2_70B    0.893491\n",
      "GPT3.5        0.880354\n",
      "GPT4          0.872205\n",
      "Name: sim_2_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.889834\n",
      "Llama2_70B    0.881750\n",
      "Palm2         0.880973\n",
      "GPT3.5        0.874013\n",
      "GPT4          0.868862\n",
      "Name: sim_2_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.896500\n",
      "Llama2_70B    0.888919\n",
      "Palm2         0.880303\n",
      "GPT4          0.878000\n",
      "GPT3.5        0.873326\n",
      "Name: sim_3_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.892406\n",
      "Llama2_70B    0.889636\n",
      "GPT4          0.885964\n",
      "Palm2         0.884926\n",
      "GPT3.5        0.876824\n",
      "Name: sim_3_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.899907\n",
      "Palm2         0.894384\n",
      "Llama2_70B    0.891967\n",
      "GPT4          0.890297\n",
      "GPT3.5        0.888007\n",
      "Name: sim_3_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.912189\n",
      "Llama2_70B    0.894324\n",
      "Palm2         0.892066\n",
      "GPT4          0.891008\n",
      "GPT3.5        0.888567\n",
      "Name: sim_4_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Llama2_70B    0.895211\n",
      "Mistral_7B    0.893005\n",
      "GPT4          0.891909\n",
      "GPT3.5        0.882868\n",
      "Palm2         0.877481\n",
      "Name: sim_4_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.893286\n",
      "GPT4          0.892916\n",
      "GPT3.5        0.887356\n",
      "Llama2_70B    0.886581\n",
      "Palm2         0.877177\n",
      "Name: sim_5_6, dtype: float64\n",
      "--------------------------------------------------\n",
      "PS2\n",
      "\n",
      "Model\n",
      "GPT3.5        0.900574\n",
      "LLama2_70B    0.896562\n",
      "Palm2         0.895860\n",
      "Mistral_7B    0.888480\n",
      "GPT4          0.879843\n",
      "Name: sim_1_2, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.882152\n",
      "GPT3.5        0.878588\n",
      "Palm2         0.872047\n",
      "LLama2_70B    0.869452\n",
      "GPT4          0.867233\n",
      "Name: sim_1_3, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.885541\n",
      "GPT3.5        0.879470\n",
      "LLama2_70B    0.874973\n",
      "Palm2         0.874677\n",
      "GPT4          0.864472\n",
      "Name: sim_1_4, dtype: float64\n",
      "\n",
      "Model\n",
      "LLama2_70B    0.877737\n",
      "Mistral_7B    0.876833\n",
      "GPT3.5        0.873577\n",
      "Palm2         0.868069\n",
      "GPT4          0.865507\n",
      "Name: sim_1_5, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT3.5        0.881345\n",
      "LLama2_70B    0.870209\n",
      "Mistral_7B    0.869172\n",
      "GPT4          0.866859\n",
      "Palm2         0.860263\n",
      "Name: sim_1_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.902090\n",
      "Mistral_7B    0.887666\n",
      "GPT4          0.880526\n",
      "GPT3.5        0.878855\n",
      "LLama2_70B    0.867725\n",
      "Name: sim_2_3, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.905131\n",
      "Mistral_7B    0.889010\n",
      "GPT3.5        0.880275\n",
      "GPT4          0.878617\n",
      "LLama2_70B    0.876435\n",
      "Name: sim_2_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.894692\n",
      "Mistral_7B    0.886081\n",
      "GPT4          0.884358\n",
      "LLama2_70B    0.875877\n",
      "GPT3.5        0.867862\n",
      "Name: sim_2_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.895852\n",
      "Mistral_7B    0.882302\n",
      "GPT4          0.879819\n",
      "GPT3.5        0.875255\n",
      "LLama2_70B    0.870781\n",
      "Name: sim_2_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Mistral_7B    0.887295\n",
      "Palm2         0.885448\n",
      "GPT3.5        0.881714\n",
      "GPT4          0.871351\n",
      "LLama2_70B    0.870573\n",
      "Name: sim_3_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.897825\n",
      "Mistral_7B    0.889633\n",
      "LLama2_70B    0.881157\n",
      "GPT3.5        0.876167\n",
      "GPT4          0.873260\n",
      "Name: sim_3_5, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.890156\n",
      "Mistral_7B    0.890048\n",
      "Palm2         0.889823\n",
      "LLama2_70B    0.881745\n",
      "GPT3.5        0.880715\n",
      "Name: sim_3_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.895534\n",
      "Mistral_7B    0.892112\n",
      "LLama2_70B    0.883673\n",
      "GPT4          0.878771\n",
      "GPT3.5        0.877682\n",
      "Name: sim_4_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.895188\n",
      "Mistral_7B    0.888573\n",
      "GPT3.5        0.882324\n",
      "LLama2_70B    0.878728\n",
      "GPT4          0.873916\n",
      "Name: sim_4_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.894547\n",
      "Mistral_7B    0.891000\n",
      "LLama2_70B    0.890835\n",
      "GPT3.5        0.876908\n",
      "GPT4          0.874846\n",
      "Name: sim_5_6, dtype: float64\n",
      "--------------------------------------------------\n",
      "PS3\n",
      "\n",
      "Model\n",
      "Palm2         0.900299\n",
      "LLama2_70B    0.888081\n",
      "GPT4          0.885967\n",
      "Mistral_7B    0.883712\n",
      "GPT3.5        0.882590\n",
      "Name: sim_1_2, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.883207\n",
      "Mistral_7B    0.870048\n",
      "GPT3.5        0.868263\n",
      "Palm2         0.867919\n",
      "LLama2_70B    0.858064\n",
      "Name: sim_1_3, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.887553\n",
      "GPT4          0.885517\n",
      "GPT3.5        0.869839\n",
      "Mistral_7B    0.869340\n",
      "LLama2_70B    0.856717\n",
      "Name: sim_1_4, dtype: float64\n",
      "\n",
      "Model\n",
      "LLama2_70B    0.881443\n",
      "GPT4          0.881333\n",
      "Palm2         0.879762\n",
      "GPT3.5        0.874028\n",
      "Mistral_7B    0.872763\n",
      "Name: sim_1_5, dtype: float64\n",
      "\n",
      "Model\n",
      "LLama2_70B    0.883306\n",
      "GPT4          0.880244\n",
      "GPT3.5        0.873196\n",
      "Palm2         0.871957\n",
      "Mistral_7B    0.869924\n",
      "Name: sim_1_6, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT3.5        0.874675\n",
      "GPT4          0.870931\n",
      "Palm2         0.868657\n",
      "Mistral_7B    0.866398\n",
      "LLama2_70B    0.863589\n",
      "Name: sim_2_3, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.888348\n",
      "GPT4          0.877542\n",
      "Mistral_7B    0.874941\n",
      "GPT3.5        0.870656\n",
      "LLama2_70B    0.864558\n",
      "Name: sim_2_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.889780\n",
      "LLama2_70B    0.872082\n",
      "Mistral_7B    0.872040\n",
      "GPT3.5        0.867632\n",
      "GPT4          0.867209\n",
      "Name: sim_2_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.875190\n",
      "Mistral_7B    0.872473\n",
      "GPT3.5        0.870673\n",
      "LLama2_70B    0.868440\n",
      "GPT4          0.868310\n",
      "Name: sim_2_6, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.878645\n",
      "Mistral_7B    0.878176\n",
      "Palm2         0.876133\n",
      "GPT3.5        0.870081\n",
      "LLama2_70B    0.867953\n",
      "Name: sim_3_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.886077\n",
      "GPT4          0.882738\n",
      "GPT3.5        0.876792\n",
      "Mistral_7B    0.868142\n",
      "LLama2_70B    0.863200\n",
      "Name: sim_3_5, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.886955\n",
      "Palm2         0.883087\n",
      "GPT3.5        0.879789\n",
      "Mistral_7B    0.872136\n",
      "LLama2_70B    0.859539\n",
      "Name: sim_3_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.885881\n",
      "GPT4          0.882766\n",
      "GPT3.5        0.874919\n",
      "Mistral_7B    0.873562\n",
      "LLama2_70B    0.864587\n",
      "Name: sim_4_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.883549\n",
      "GPT4          0.877799\n",
      "GPT3.5        0.877258\n",
      "Mistral_7B    0.870941\n",
      "LLama2_70B    0.862665\n",
      "Name: sim_4_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.889945\n",
      "GPT4          0.888313\n",
      "LLama2_70B    0.885493\n",
      "GPT3.5        0.884856\n",
      "Mistral_7B    0.878150\n",
      "Name: sim_5_6, dtype: float64\n",
      "--------------------------------------------------\n",
      "PS4\n",
      "\n",
      "Model\n",
      "Palm2         0.893797\n",
      "LLama2_70B    0.891647\n",
      "GPT3.5        0.883077\n",
      "GPT4          0.875728\n",
      "Mistral_7B    0.874540\n",
      "Name: sim_1_2, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.879263\n",
      "GPT3.5        0.876629\n",
      "Mistral_7B    0.868836\n",
      "LLama2_70B    0.867159\n",
      "Palm2         0.856501\n",
      "Name: sim_1_3, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.878461\n",
      "GPT3.5        0.874940\n",
      "Mistral_7B    0.874532\n",
      "LLama2_70B    0.873708\n",
      "Palm2         0.868419\n",
      "Name: sim_1_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.884495\n",
      "GPT4          0.872567\n",
      "GPT3.5        0.871885\n",
      "Mistral_7B    0.871038\n",
      "LLama2_70B    0.867019\n",
      "Name: sim_1_5, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.875725\n",
      "GPT3.5        0.871540\n",
      "Palm2         0.870688\n",
      "Mistral_7B    0.870353\n",
      "LLama2_70B    0.864900\n",
      "Name: sim_1_6, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.875904\n",
      "Mistral_7B    0.875559\n",
      "GPT3.5        0.874304\n",
      "LLama2_70B    0.869063\n",
      "Palm2         0.862430\n",
      "Name: sim_2_3, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT3.5        0.878617\n",
      "Palm2         0.878505\n",
      "LLama2_70B    0.875385\n",
      "Mistral_7B    0.872491\n",
      "GPT4          0.870822\n",
      "Name: sim_2_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.888859\n",
      "GPT3.5        0.883886\n",
      "LLama2_70B    0.875058\n",
      "Mistral_7B    0.872975\n",
      "GPT4          0.866931\n",
      "Name: sim_2_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.876591\n",
      "GPT3.5        0.872756\n",
      "GPT4          0.867448\n",
      "LLama2_70B    0.866667\n",
      "Mistral_7B    0.864866\n",
      "Name: sim_2_6, dtype: float64\n",
      "\n",
      "Model\n",
      "LLama2_70B    0.884963\n",
      "GPT3.5        0.884388\n",
      "GPT4          0.881206\n",
      "Mistral_7B    0.870951\n",
      "Palm2         0.868592\n",
      "Name: sim_3_4, dtype: float64\n",
      "\n",
      "Model\n",
      "LLama2_70B    0.883687\n",
      "GPT4          0.880473\n",
      "Palm2         0.873479\n",
      "GPT3.5        0.872615\n",
      "Mistral_7B    0.867330\n",
      "Name: sim_3_5, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.886734\n",
      "Palm2         0.878931\n",
      "LLama2_70B    0.878664\n",
      "GPT3.5        0.872860\n",
      "Mistral_7B    0.868073\n",
      "Name: sim_3_6, dtype: float64\n",
      "\n",
      "Model\n",
      "LLama2_70B    0.894059\n",
      "Palm2         0.884594\n",
      "GPT4          0.880315\n",
      "Mistral_7B    0.879619\n",
      "GPT3.5        0.877916\n",
      "Name: sim_4_5, dtype: float64\n",
      "\n",
      "Model\n",
      "LLama2_70B    0.881358\n",
      "GPT4          0.878137\n",
      "Palm2         0.872030\n",
      "GPT3.5        0.869469\n",
      "Mistral_7B    0.868625\n",
      "Name: sim_4_6, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.886897\n",
      "LLama2_70B    0.885203\n",
      "Mistral_7B    0.883985\n",
      "Palm2         0.882606\n",
      "GPT3.5        0.874523\n",
      "Name: sim_5_6, dtype: float64\n",
      "--------------------------------------------------\n",
      "PS5\n",
      "\n",
      "Model\n",
      "Palm2         0.889939\n",
      "GPT4          0.884546\n",
      "LLama2_70B    0.881241\n",
      "Mistral_7B    0.875830\n",
      "GPT3.5        0.871703\n",
      "Name: sim_1_2, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT3.5        0.866909\n",
      "GPT4          0.866616\n",
      "Palm2         0.865031\n",
      "Mistral_7B    0.863494\n",
      "LLama2_70B    0.858491\n",
      "Name: sim_1_3, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.873657\n",
      "GPT4          0.872210\n",
      "GPT3.5        0.871576\n",
      "Mistral_7B    0.862822\n",
      "LLama2_70B    0.858945\n",
      "Name: sim_1_4, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.874515\n",
      "Palm2         0.871358\n",
      "GPT3.5        0.866289\n",
      "LLama2_70B    0.864128\n",
      "Mistral_7B    0.862058\n",
      "Name: sim_1_5, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.877904\n",
      "GPT3.5        0.867578\n",
      "LLama2_70B    0.865926\n",
      "Mistral_7B    0.860226\n",
      "Palm2         0.858930\n",
      "Name: sim_1_6, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.879080\n",
      "GPT3.5        0.872263\n",
      "Mistral_7B    0.867875\n",
      "Palm2         0.866698\n",
      "LLama2_70B    0.865224\n",
      "Name: sim_2_3, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.878388\n",
      "Palm2         0.876993\n",
      "Mistral_7B    0.869916\n",
      "GPT3.5        0.865456\n",
      "LLama2_70B    0.865065\n",
      "Name: sim_2_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.879032\n",
      "GPT3.5        0.872560\n",
      "GPT4          0.870851\n",
      "LLama2_70B    0.868038\n",
      "Mistral_7B    0.865019\n",
      "Name: sim_2_5, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.871549\n",
      "Palm2         0.864319\n",
      "GPT3.5        0.863917\n",
      "LLama2_70B    0.863459\n",
      "Mistral_7B    0.862293\n",
      "Name: sim_2_6, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT3.5        0.870185\n",
      "LLama2_70B    0.869852\n",
      "GPT4          0.868489\n",
      "Mistral_7B    0.868156\n",
      "Palm2         0.865149\n",
      "Name: sim_3_4, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.877529\n",
      "GPT4          0.872501\n",
      "LLama2_70B    0.871922\n",
      "GPT3.5        0.867495\n",
      "Mistral_7B    0.862347\n",
      "Name: sim_3_5, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.887494\n",
      "GPT4          0.877492\n",
      "GPT3.5        0.865028\n",
      "LLama2_70B    0.864434\n",
      "Mistral_7B    0.862038\n",
      "Name: sim_3_6, dtype: float64\n",
      "\n",
      "Model\n",
      "Palm2         0.883885\n",
      "LLama2_70B    0.876132\n",
      "GPT4          0.871812\n",
      "Mistral_7B    0.870244\n",
      "GPT3.5        0.866596\n",
      "Name: sim_4_5, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.875775\n",
      "GPT3.5        0.867806\n",
      "Mistral_7B    0.865027\n",
      "LLama2_70B    0.863017\n",
      "Palm2         0.859461\n",
      "Name: sim_4_6, dtype: float64\n",
      "\n",
      "Model\n",
      "GPT4          0.892089\n",
      "LLama2_70B    0.881931\n",
      "Palm2         0.880984\n",
      "GPT3.5        0.873720\n",
      "Mistral_7B    0.868319\n",
      "Name: sim_5_6, dtype: float64\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "file_paths = ['Large Model Questions.xlsx']\n",
    "\n",
    "for file_path in file_paths:\n",
    "    print(\"-\"*50)\n",
    "    print(file_path)\n",
    "    print(\"-\"*50)\n",
    "    for sheet_name in ['PS1','PS2','PS3','PS4','PS5']:\n",
    "        print(sheet_name)\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df['Prompt'] = df['Prompt'].ffill()\n",
    "        df['Model'] = df['Model'].ffill()\n",
    "    \n",
    "        print()\n",
    "        avg_similarity_12 = df.groupby('Model')['sim_1_2'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_13 = df.groupby('Model')['sim_1_3'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_14 = df.groupby('Model')['sim_1_4'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_15 = df.groupby('Model')['sim_1_5'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_16 = df.groupby('Model')['sim_1_6'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_23 = df.groupby('Model')['sim_2_3'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_24 = df.groupby('Model')['sim_2_4'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_25 = df.groupby('Model')['sim_2_5'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_26 = df.groupby('Model')['sim_2_6'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_34 = df.groupby('Model')['sim_3_4'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_35 = df.groupby('Model')['sim_3_5'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_36 = df.groupby('Model')['sim_3_6'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_45 = df.groupby('Model')['sim_4_5'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_46 = df.groupby('Model')['sim_4_6'].mean().sort_values(ascending=False)\n",
    "        avg_similarity_56 = df.groupby('Model')['sim_5_6'].mean().sort_values(ascending=False)\n",
    "        \n",
    "        print(avg_similarity_12, avg_similarity_13, avg_similarity_14, avg_similarity_15, avg_similarity_16, avg_similarity_23, avg_similarity_24, avg_similarity_25, avg_similarity_26, avg_similarity_34, avg_similarity_35, avg_similarity_36, avg_similarity_45, avg_similarity_46, avg_similarity_56, sep=\"\\n\\n\")\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4e9e868-0025-4739-ad71-e263c5f2c9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Wrote BERTScore_Summary_Small.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.styles import Alignment, Font, PatternFill, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# -------- settings --------\n",
    "src_path = \"Small Model Question (1).xlsx\"\n",
    "dst_path = \"BERTScore_Summary_Small.xlsx\"\n",
    "sheets = [\"PS1\", \"PS2\", \"PS3\", \"PS4\", \"PS5\"]\n",
    "pairs = [\"1_2\",\"1_3\",\"1_4\",\"1_5\",\"1_6\",\"2_3\",\"2_4\",\"2_5\",\"2_6\",\"3_4\",\"3_5\",\"3_6\",\"4_5\",\"4_6\",\"5_6\"]\n",
    "pair_labels = {p: p.replace(\"_\",\"\") for p in pairs}\n",
    "# --------------------------\n",
    "\n",
    "def prep(df):\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if \"Prompt\" in df: \n",
    "        df[\"Prompt\"] = df[\"Prompt\"].ffill()\n",
    "    df[\"Model\"] = df[\"Model\"].ffill()\n",
    "    return df\n",
    "\n",
    "def per_pair_means(df):\n",
    "    out = {}\n",
    "    for p in pairs:\n",
    "        col = f\"sim_{p}\"\n",
    "        s = df.groupby(\"Model\")[col].mean()\n",
    "        out[p] = s\n",
    "    return out\n",
    "\n",
    "# load sheets\n",
    "dfs = {sn: prep(pd.read_excel(src_path, sheet_name=sn)) for sn in sheets}\n",
    "df_total = prep(pd.concat(dfs.values(), ignore_index=True))\n",
    "dfs[\"Total\"] = df_total\n",
    "\n",
    "means = {sn: per_pair_means(df) for sn, df in dfs.items()}\n",
    "\n",
    "all_models = pd.Index(\n",
    "    pd.concat([df[\"Model\"] for df in dfs.values()]).dropna().unique()\n",
    ")\n",
    "n_models = len(all_models)\n",
    "\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "ws.title = \"Summary\"\n",
    "\n",
    "top_row = 1\n",
    "for j, p in enumerate(pairs):\n",
    "    c0 = j*2 + 1\n",
    "    ws.merge_cells(start_row=top_row, start_column=c0,\n",
    "                   end_row=top_row, end_column=c0+1)\n",
    "    cell = ws.cell(row=top_row, column=c0, value=pair_labels[p])\n",
    "\n",
    "# blocks for PS1..PS5 + Total\n",
    "block_height = 2 + n_models + 1  # block title + header + models + spacer\n",
    "for b, sheet_name in enumerate(list(sheets) + [\"Total\"]):\n",
    "    start_r = 2 + b*block_height\n",
    "    for j, p in enumerate(pairs):\n",
    "        c0 = j*2 + 1\n",
    "\n",
    "        # Block title\n",
    "        ws.merge_cells(start_row=start_r, start_column=c0,\n",
    "                       end_row=start_r, end_column=c0+1)\n",
    "        cell = ws.cell(row=start_r, column=c0, value=sheet_name)\n",
    "\n",
    "        # Data rows\n",
    "        s = means[sheet_name][p]\n",
    "        r = start_r + 2\n",
    "        for model, score in s.items():\n",
    "            ws.cell(row=r, column=c0, value=model)\n",
    "            ws.cell(row=r, column=c0+1, value=score)\n",
    "            r += 1\n",
    "\n",
    "# save file\n",
    "wb.save(dst_path)\n",
    "print(f\"Done. Wrote {dst_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d31ca-b929-495e-b984-64e526eb9279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
