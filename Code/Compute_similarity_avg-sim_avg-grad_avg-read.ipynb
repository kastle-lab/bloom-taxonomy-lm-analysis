{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3BBS-nbczs1"
   },
   "outputs": [],
   "source": [
    "file_path = 'Large_Model_Questions_WITH_BERTSCORE_PRF_debertaxlargemnli.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "052LsixH_lbr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils import get_column_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "052LsixH_lbr"
   },
   "outputs": [],
   "source": [
    "# Load gtr-t5-large model ONCE\n",
    "model = SentenceTransformer('sentence-transformers/gtr-t5-large')\n",
    "\n",
    "# Get all sheet names\n",
    "xls = pd.ExcelFile(file_path)\n",
    "sheet_names = xls.sheet_names\n",
    "\n",
    "temp_path = 'temp_all_sheets.xlsx'\n",
    "output_path = \"grouped_output_merged_ALLSHEETS_WITH_BERTSCORE_PRF_debertaxlargemnli.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "VwjjdvpASC4V",
    "outputId": "184c4f51-f6da-43b2-c667-10f62b69fe3e"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Part 1: process + write all sheets\n",
    "# -----------------------------\n",
    "with pd.ExcelWriter(temp_path, engine=\"openpyxl\") as writer:\n",
    "    for sheet_name in sheet_names:\n",
    "        # Load your data\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df['Prompt'] = df['Prompt'].ffill()\n",
    "\n",
    "        # Generate embeddings\n",
    "        prompt_embeddings = model.encode(df['Prompt'].tolist(), convert_to_tensor=True)\n",
    "        question_embeddings = model.encode(df['Questions'].tolist(), convert_to_tensor=True)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        cosine_similarities = util.cos_sim(prompt_embeddings, question_embeddings).diagonal().cpu().numpy()\n",
    "        df['similarity'] = cosine_similarities.round(2) \n",
    "\n",
    "        # Group by model\n",
    "        avg_similarity = df.groupby('Model')['similarity'].mean().sort_values(ascending=False)\n",
    "        print(f\"\\n=== {sheet_name} ===\")\n",
    "        print(avg_similarity)\n",
    "\n",
    "        df_ps1 = df.copy()\n",
    "        df_ps1.insert(3, \"Bloom's level\", ([1,2,3,4,5,6] * ((len(df) // 6) + 1))[:len(df)])\n",
    "\n",
    "\n",
    "        # Generate a group ID for each block of 6 consecutive rows per model\n",
    "        df_ps1['group_id'] = df_ps1.groupby('Model').cumcount() // 6\n",
    "\n",
    "        # Compute averages per model per prompt group\n",
    "        df_ps1['avg_similarity_per_prompt'] = df_ps1.groupby(['group_id', 'Model'])['similarity'].transform('mean')\n",
    "        df_ps1['Avg Grade Level'] = df_ps1.groupby(['group_id', 'Model'])['Grade level'].transform('mean')\n",
    "        df_ps1['Avg Reading Ease'] = df_ps1.groupby(['group_id', 'Model'])['Reading Ease'].transform('mean')\n",
    "\n",
    "        df_ps1.drop(columns=['group_id'], inplace=True)\n",
    "\n",
    "        # Write processed sheet\n",
    "        df_ps1.to_excel(writer, sheet_name=sheet_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VH5rgE8VRrfP"
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Part 2: reopen and merge cells in EACH sheet\n",
    "# -----------------------------\n",
    "wb = load_workbook(temp_path)\n",
    "\n",
    "# Define which columns to merge and how many rows per group\n",
    "columns_to_merge = [\n",
    "    ('Prompt', 48),\n",
    "    ('Model', 6),\n",
    "    ('avg_similarity_per_prompt', 6),\n",
    "    ('Avg Grade Level', 6),\n",
    "    ('Avg Reading Ease', 6),\n",
    "]\n",
    "\n",
    "for sheet_name in wb.sheetnames:\n",
    "    ws = wb[sheet_name]\n",
    "\n",
    "    # Map column names to Excel column letters\n",
    "    header = {cell.value: idx + 1 for idx, cell in enumerate(ws[1])}\n",
    "\n",
    "    for col_name, group_size in columns_to_merge:\n",
    "        if col_name not in header:\n",
    "            continue  # skip if column missing in that sheet\n",
    "\n",
    "        col_idx = header[col_name]\n",
    "        col_letter = get_column_letter(col_idx)\n",
    "\n",
    "        for start_row in range(2, ws.max_row + 1, group_size):  # Start from row 2 (skip header)\n",
    "            end_row = min(start_row + group_size - 1, ws.max_row)\n",
    "            if start_row != end_row:  # Only merge if more than 1 row\n",
    "                ws.merge_cells(f\"{col_letter}{start_row}:{col_letter}{end_row}\")\n",
    "\n",
    "wb.save(output_path)\n",
    "print(f\"\\nSaved merged workbook: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbXGxeM0ZUOM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
